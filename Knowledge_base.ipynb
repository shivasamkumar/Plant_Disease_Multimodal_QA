{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "362d6e38-c1af-4ef3-800a-f56bd0435cc2",
   "metadata": {},
   "source": [
    "## Agriculture Knowledge Base \n",
    "\n",
    "### This workbook demonstrates how to create a knowledge base.\n",
    "### In the next part we would use this knowledge base to create tools through GPT API calls. \n",
    "### The agent needs to be accurate, and the solution should be low cost.\n",
    "\n",
    "This project will use RAG (Retrieval Augmented Generation) to ensure our question/answering assistant has high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b2eb06-cdff-454a-a5dd-ba0bbb81cab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7c6854-d47f-49d1-b799-7af43504d480",
   "metadata": {},
   "source": [
    "**This cell creates a website class to get the components of the website**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7106384-b3eb-4c54-92de-fbf4f3dcdcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# The links are also stored which can be used to enhance the chatbot\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49549c20-a57b-4aa5-9d7f-1d2fc3f14734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fe1a96-75fd-4320-ad01-7da8431ae4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiation of the CSV and the Base folder \n",
    "CSV_PATH = 'diseases_with_links.csv'\n",
    "ROOT_DIR = 'Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4286d384-d006-437a-99de-16794d473e77",
   "metadata": {},
   "source": [
    "## Helper Functions \n",
    "* ### Scrape the Website Content \n",
    "* ### To create folder structure\n",
    "* ### Using Gpt Api to create markdown from the web content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa8ae8-5490-4fac-a144-d78d5404cc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scrapping function using beautiful soup\n",
    "def get_all_details(url):\n",
    "    \"\"\"\n",
    "    Fetches the full text/content of `url` and returns it as a string.\n",
    "    (You already have Website(url).get_contents() implemented.)\n",
    "    \"\"\"\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787ab834-c812-417f-aa07-b8adbbf156bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# —————————————————————————————\n",
    "# FUNCTION 1: BUILD FOLDER STRUCTURE\n",
    "# —————————————————————————————\n",
    "\n",
    "def build_folder_structure(csv_path: str, root_dir: str):\n",
    "    \"\"\"\n",
    "    Reads csv_path for 'disease' and 'keyword' columns,\n",
    "    then creates:\n",
    "        root_dir/knowledge_base/<disease>/<keyword>/\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, converters={'links': ast.literal_eval})\n",
    "    for _, row in df.iterrows():\n",
    "        disease = row['disease']\n",
    "        keyword = row['keyword']\n",
    "        folder = os.path.join(root_dir, 'knowledge_base', disease, keyword)\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"Folder tree created under {root_dir}/knowledge_base/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999c8fa-7119-476a-a799-2738a0eddfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_user_prompt(disease: str, keyword: str, page_content: str) -> str:\n",
    "    return (\n",
    "        f\"Here is the full text for **{disease}** ({keyword}):\\n\\n\"\n",
    "        f\"{page_content}\\n\\n\"\n",
    "        \"Please distill that into a detailed Markdown with appropriate headings and bullet points,\"\n",
    "        \"Make sure You don't add anything unecessary thimgs like add content , emails etc and extra content, which is not provided to you.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d137908-788d-43e7-ac24-da37a7925f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_markdown_from_links(\n",
    "    csv_path: str,\n",
    "    root_dir: str,\n",
    "    start_disease: str = None,\n",
    "    start_row: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    Reads csv_path for 'disease', 'keyword', and 'links'.\n",
    "    - If start_disease is given, skips all diseases until name matches.\n",
    "    - If start_row > 0, skips that many rows in the DataFrame first.\n",
    "    For each surviving row it:\n",
    "      * Iterates links, fetching page text and summarizing.\n",
    "      * On any SSL or other error, logs & skips that link.\n",
    "      * Writes out <idx>.md into root_dir/knowledge_base/<disease>/<keyword>/\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path, converters={'links': ast.literal_eval})\n",
    "    total_rows = len(df)\n",
    "    started = start_disease is None  # if no disease specified, start immediately\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "        # skip leading rows if requested\n",
    "        if row_idx < start_row:\n",
    "            continue\n",
    "\n",
    "        disease = row['disease']\n",
    "        keyword = row['keyword']\n",
    "        links   = row['links']\n",
    "        base_folder = os.path.join(root_dir, 'knowledge_base', disease, keyword)\n",
    "\n",
    "        # skip until we hit start_disease\n",
    "        if not started:\n",
    "            if disease != start_disease:\n",
    "                print(f\"Skipping disease {disease!r} until we reach {start_disease!r}\")\n",
    "                continue\n",
    "            print(f\"Starting at disease {disease!r}\")\n",
    "            started = True\n",
    "\n",
    "        os.makedirs(base_folder, exist_ok=True)\n",
    "\n",
    "        for idx, url in enumerate(links, start=1):\n",
    "            try:\n",
    "                print(f\"[{disease}/{keyword}] [{row_idx+1}/{total_rows}] link #{idx}: fetching content…\")\n",
    "                page_content = get_all_details(url)\n",
    "\n",
    "                user_prompt = make_user_prompt(disease, keyword, page_content)\n",
    "                print(f\"[{disease}/{keyword}] summarizing link #{idx} via GPT…\")\n",
    "                resp = openai.chat.completions.create(\n",
    "                    model=MODEL,\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\",  \"content\": SYSTEM_PROMPT},\n",
    "                        {\"role\": \"user\",    \"content\": user_prompt}\n",
    "                    ],\n",
    "                )\n",
    "                md_content = resp.choices[0].message.content\n",
    "\n",
    "                # write the markdown file\n",
    "                md_path = os.path.join(base_folder, f\"{idx}.md\")\n",
    "                with open(md_path, 'w', encoding='utf-8') as f:\n",
    "                    f.write(md_content)\n",
    "\n",
    "            except (UrllibSSLError, ssl.SSLError) as e:\n",
    "                print(f\" SSL error on {url!r}: {e}. Skipping this link.\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\" Error processing link {url!r}: {e}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        # end of links for this disease → next row automatically\n",
    "\n",
    "    print(\" Done generating Markdown files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdd162-df6e-4b53-a326-1d9e24937fe6",
   "metadata": {},
   "source": [
    "## Initiation and calling the Functions to genrate Markdown files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bdc1b1-93ce-4a4c-acf0-7cb37a1333f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiation of the CSV and the Base folder \n",
    "CSV_PATH = 'diseases_with_links.csv'\n",
    "ROOT_DIR = 'Data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb44f7-5077-4f3d-92ab-d4d6c31c54c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb8d74a-d2fa-4e11-9dd0-35f4b12e08b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_folder_structure(CSV_PATH, ROOT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a62468-d4c8-45fe-a734-04ace99daa4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'gpt-4o-mini'  # or whichever model you prefer\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an expert Agricultural specialist writer. \"\n",
    "    \"Given the full page content for a disease under one of two categories (About/Cure), \"\n",
    "    \"produce a Markdown document with headings ### About and ### Cure as appropriate.\"\n",
    "    \"Don't give unecessary information try to use only the information given to you.\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb2d8c7-736c-4500-a5dc-e6f45ffc908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_markdown_from_links(CSV_PATH, ROOT_DIR, start_row=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
